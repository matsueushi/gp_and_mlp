{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Process and Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ColorSchemes\n",
    "using Optim\n",
    "using Plots\n",
    "using Printf\n",
    "using Statistics\n",
    "using LaTeXStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"gp.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from 1D Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xs = collect(range(-5, stop = 5, length = 100))\n",
    "\n",
    "gp = GaussianProcess(GaussianKernel(1, 1))\n",
    "Plots.plot(xs, rand(dist(gp, xs), 5), \n",
    "    label = \"\", xlabel = \"x\", ylabel = \"f\",\n",
    "    linewidth = 2,\n",
    "    title = \"Sampling from f ~ GP(0, K)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = [1:4, 1:0.5:4, 1:0.2:4]\n",
    "yy = [1, 0.5, 0.2]\n",
    "\n",
    "plts = []\n",
    "for (x, y) in zip(xx, yy)\n",
    "    x1 = collect(x)\n",
    "    n = Base.length(x)\n",
    "    sample = rand(dist(gp, x1))\n",
    "    sample_min = minimum(sample)\n",
    "    sample_plot = scatter(x, sample, label = \"\",\n",
    "            markershape = :utriangle, markercolor = :red,\n",
    "            title = @sprintf(\"Sample, Step=%.1f\", y), titlefontsize = 10)\n",
    "    scatter!(x, fill(sample_min - 0.3, n),\n",
    "        xlims = (0.5, 4.5),\n",
    "        ylims = (sample_min - 0.5, maximum(sample) + 0.5),\n",
    "        markershape = :x, markerstrokewidth = 2,\n",
    "        label = \"\")\n",
    "    push!(plts, sample_plot)\n",
    "    push!(plts, heatmap(x1, x1, cov(gp, x1), \n",
    "            title = \"Covariance matrix\", titlefontsize = 10,\n",
    "            aspect_ratio = :equal, yflip = true, color = cgrad([:white, :blue])))\n",
    "end\n",
    "\n",
    "Plots.plot(plts..., layout = (3, 2), size = [600, 600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from 2D Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = 0:0.05:1, 0:0.05:1\n",
    "n1, n2 = Base.length(x1), Base.length(x2)\n",
    "n = n1 * n2\n",
    "pt = permutedims(hcat([[i, j] for i in x1, j in x2]...));\n",
    "sample = rand(dist(gp, pt), 2)\n",
    "\n",
    "plts = []\n",
    "for i in 1:2\n",
    "    z = reshape(sample[:, i], n1, n2)\n",
    "    push!(plts,\n",
    "        surface(x1, x2, z, alpha = 0.8, camera = (40, 60),\n",
    "        seriescolor = cgrad(ColorSchemes.jet1.colors), \n",
    "        linewidth = 2,\n",
    "        framestyle = :grid,\n",
    "        xlabel = \"x1\", ylabel = \"x2\", zlabel = \"f\"))\n",
    "end\n",
    "Plots.plot(plts..., layout = (1, 2), size = [700, 250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Types (Linear, Gaussian, Exponential, Periodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = collect(range(-5, stop = 5, length = 100))\n",
    "kernels = [LinearKernel(), GaussianKernel(1, 1),\n",
    "           ExponentialKernel(1), PeriodicKernel(1.0, 0.5)]\n",
    "plts = []\n",
    "\n",
    "for k in kernels\n",
    "    gp = GaussianProcess(k)\n",
    "    p = Plots.plot(xs, rand(dist(gp, xs), 4), label = \"\", linewidth = 2, title = @sprintf(\"%s\", k))\n",
    "    push!(plts, p)\n",
    "end\n",
    "    \n",
    "Plots.plot(plts..., layout = (2, 2), size = [800, 600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = collect(range(-5, stop = 5, length = 100))\n",
    "l_ker = 2.0 * LinearKernel() + 3.0 * PeriodicKernel(1.0, 0.5)\n",
    "\n",
    "gp = GaussianProcess(l_ker)\n",
    "Plots.plot(xs, rand(dist(gp, xs), 5), \n",
    "    label = \"\", size = [400, 300],\n",
    "    linewidth = 2,\n",
    "    title = \"2 * LinearKernel() + 3 * PeriodicKernel(1.0, 0.5)\", titlefontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatÃ©rn kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = collect(range(-5, stop = 5, length = 100))\n",
    "kernels = [MaternKernel(3/2, 1.), MaternKernel(5/2, 1.)]\n",
    "plts = []\n",
    "\n",
    "for k in kernels\n",
    "    gp = GaussianProcess(k)\n",
    "    p = Plots.plot(xs, rand(dist(gp, xs), 4), label = \"\", linewidth = 2, title = @sprintf(\"%s\", k))\n",
    "    push!(plts, p)\n",
    "end\n",
    "    \n",
    "Plots.plot(plts..., layout = (1, 2), size = [800, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [-0.5, 0.5, 1, 1.4, 3]\n",
    "ys = [0.7, 1.8, 1.7, 2.3, 1]\n",
    "gp = GaussianProcess(GaussianKernel(1.0, 0.4), 0.01)\n",
    "xtrain = collect(range(-1, stop=3.5, length=100))\n",
    "pred = gpr(gp, xtrain, xs, ys)\n",
    "qt = mapslices(x -> quantile(x, [0.025, 0.925]), rand(pred, 10000), dims = 2)\n",
    "\n",
    "Plots.plot(xtrain, qt[:, 1], fillrange = qt[:, 2], fillalpha = 0.3,\n",
    "    label = \"\", linewidth = 0)\n",
    "Plots.plot!(xtrain, mean(pred), label = \"Mean\", linewidth = 2, linestyle = :dash)\n",
    "Plots.plot!(xtrain, rand(pred, 10), label = \"\", linewidth = 1, linealpha = 0.5)\n",
    "\n",
    "scatter!(xs, ys, label = \"\", title = \"Posterior distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [-0.5, 0.5, 1, 1.4, 3]\n",
    "ys = [0.7, 1.8, 1.7, 2.3, 1]\n",
    "\n",
    "pc1 = ParamCalibrator(GaussianProcess(GaussianKernel(1, 1), 1), xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization with gradient, GradientDescent\n",
    "# we minimize -logp instead of maximize logp\n",
    "\n",
    "lower = fill(-30.0, 3)\n",
    "upper = fill(30.0, 3)\n",
    "\n",
    "res = optimize(\n",
    "    Optim.only_fg!((F, G, x) -> fg!(pc1, F, G, x)),\n",
    "    lower, upper, [0.0, 0.0, 0.0], \n",
    "    Fminbox(GradientDescent()))\n",
    "\n",
    "println(res)\n",
    "pars = Optim.minimizer(res)\n",
    "println(\"[theta1, theta2, theta3] = \", exp.(pars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization with gradient, L-BFGS\n",
    "lower = fill(-30.0, 3)\n",
    "upper = fill(30.0, 3)\n",
    "\n",
    "res = optimize(\n",
    "    Optim.only_fg!((F, G, x) -> fg!(pc1, F, G, x)),\n",
    "    lower, upper, [0.0, 0.0, 0.0], \n",
    "    Fminbox(LBFGS()))\n",
    "\n",
    "println(res)\n",
    "pars = Optim.minimizer(res)\n",
    "println(\"[theta1, theta2, theta3] = \", exp.(pars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update!(pc1, pars)\n",
    "xtrain = collect(range(-1, stop=3.5, length=100))\n",
    "pred = gpr(pc1.gp, xtrain, pc1.xs, pc1.ys)\n",
    "qt = mapslices(x -> quantile(x, [0.025, 0.975]), rand(pred, 10000), dims = 2)\n",
    "\n",
    "Plots.plot(xtrain, qt[:, 1], fillrange = qt[:, 2], fillalpha = 0.3,\n",
    "    label = \"\", linewidth = 0)\n",
    "Plots.plot!(xtrain, mean(pred), label = \"Mean\", linewidth = 2, linestyle = :dash)\n",
    "\n",
    "scatter!(xs, ys, label = \"\", title = \"Posterior distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log likelihood\n",
    "logp(pc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more points\n",
    "\n",
    "xs = [-0.5, 0.5, 1, 1.4, 3, 2.3, 2.5, 1.5, 1.1, 0.7]\n",
    "ys = [0.7, 1.8, 1.7, 2.3, 1, 0, 0.2, 2, 2.4, 1.5]\n",
    "\n",
    "pc2 = ParamCalibrator(GaussianProcess(GaussianKernel(1, 1), 1), xs, ys)\n",
    "res = optimize(\n",
    "    Optim.only_fg!((F, G, x) -> fg!(pc2, F, G, x)),\n",
    "    lower, upper, [0.0, 0.0, 0.0], \n",
    "    Fminbox(LBFGS()))\n",
    "\n",
    "println(res)\n",
    "pars = Optim.minimizer(res)\n",
    "println(\"[theta1, theta2, theta3] = \", exp.(pars))\n",
    "\n",
    "update!(pc2, pars)\n",
    "xtrain = collect(range(-1, stop=3.5, length=100))\n",
    "pred = gpr(pc2.gp, xtrain, pc2.xs, pc2.ys)\n",
    "qt = mapslices(x -> quantile(x, [0.025, 0.975]), rand(pred, 10000), dims = 2)\n",
    "\n",
    "Plots.plot(xtrain, qt[:, 1], fillrange = qt[:, 2], fillalpha = 0.3,\n",
    "    label = \"\", linewidth = 0)\n",
    "Plots.plot!(xtrain, mean(pred), label = \"Mean\", linewidth = 2, linestyle = :dash)\n",
    "\n",
    "scatter!(xs, ys, label = \"\", title = \"Posterior distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log likelihood\n",
    "logp(pc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f_logp(x, y)\n",
    "    update!(pc1, [0, x, y])\n",
    "    max(-20, logp(pc1)) # set floor of logp to be -20\n",
    "end\n",
    "\n",
    "theta2, theta3 = -2.5:0.2:12, -10:0.2:2.5\n",
    "z = Surface((x, y) -> f_logp(x, y), theta2, theta3)\n",
    "contourf(theta2, theta3, z, seriescolor = cgrad(ColorSchemes.jet1.colors), \n",
    "    levels = collect(-20:0.5:-2),\n",
    "    xlabel = L\"\\log \\theta_2\", ylabel = L\"\\log \\theta_3\",\n",
    "    guidefont=font(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface(theta2, theta3, z, seriescolor = cgrad(ColorSchemes.jet1.colors), camera = (30, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = fill(-30.0, 2)\n",
    "upper = fill(30.0, 2)\n",
    "\n",
    "function fg_2!(pc::ParamCalibrator, F, G, x)\n",
    "    update!(pc, [0, x...])\n",
    "    \n",
    "    if G!= nothing\n",
    "        y = exp.(x)\n",
    "        d_tau = pc.k - y[2] .* Matrix{Float64}(I, pc.n_xs, pc.n_xs)\n",
    "        d_sigma = d_tau ./ y[1] .* pc.distance_matrix\n",
    "        d_eta = y[2] .* Matrix{Float64}(I, pc.n_xs, pc.n_xs)\n",
    "        G[1] = -deriv(pc, d_sigma)\n",
    "        G[2] = -deriv(pc, d_eta)\n",
    "    end\n",
    "    \n",
    "    if F!= nothing\n",
    "        value = -logp(pc)\n",
    "        return value\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "# starting from (0, 0)\n",
    "res = optimize(\n",
    "    Optim.only_fg!((F, G, x) -> fg_2!(pc1, F, G, x)),\n",
    "    lower, upper, [0.0, 0.0], \n",
    "    Fminbox(LBFGS()))\n",
    "\n",
    "println(res)\n",
    "pars = Optim.minimizer(res)\n",
    "println(\"logp:\", logp(pc1))\n",
    "\n",
    "update!(pc1, [0, pars...])\n",
    "xtrain = collect(range(-1, stop=3.5, length=100))\n",
    "pred = gpr(pc1.gp, xtrain, pc1.xs, pc1.ys)\n",
    "qt = mapslices(x -> quantile(x, [0.025, 0.975]), rand(pred, 10000), dims = 2)\n",
    "\n",
    "Plots.plot(xtrain, qt[:, 1], fillrange = qt[:, 2], fillalpha = 0.3,\n",
    "    label = \"\", linewidth = 0)\n",
    "Plots.plot!(xtrain, mean(pred), label = \"Mean\", linewidth = 2, linestyle = :dash)\n",
    "\n",
    "scatter!(pc1.xs, pc1.ys, label = \"\", title = \"Posterior distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting from (5, 0)\n",
    "res = optimize(\n",
    "    Optim.only_fg!((F, G, x) -> fg_2!(pc1, F, G, x)),\n",
    "    lower, upper, [5.0, 0.0], \n",
    "    Fminbox(LBFGS()))\n",
    "\n",
    "println(res)\n",
    "pars = Optim.minimizer(res)\n",
    "println(\"logp:\", logp(pc1))\n",
    "\n",
    "update!(pc1, [0, pars...])\n",
    "xtrain = collect(range(-1, stop=3.5, length=100))\n",
    "pred = gpr(pc1.gp, xtrain, pc1.xs, pc1.ys)\n",
    "qt = mapslices(x -> quantile(x, [0.025, 0.975]), rand(pred, 10000), dims = 2)\n",
    "\n",
    "Plots.plot(xtrain, qt[:, 1], fillrange = qt[:, 2], fillalpha = 0.3,\n",
    "    label = \"\", linewidth = 0)\n",
    "Plots.plot!(xtrain, mean(pred), label = \"Mean\", linewidth = 2, linestyle = :dash)\n",
    "\n",
    "scatter!(pc1.xs, pc1.ys, label = \"\", title = \"Posterior distribution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
